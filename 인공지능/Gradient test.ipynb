{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2,3], [5,1,2], [4,5,7], [4,5,6]])\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.405000000000001"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([[1,2,3,1], [4,3,7,2], [3,3,3,2], [7,1,9,3]])\n",
    "data\n",
    "x = data[:, 0:3] #feature\n",
    "y = data[: , 3:]\n",
    "w =np.array([[0.1], [0.3], [-0.2]])\n",
    "w.shape\n",
    "\n",
    "yp = np.matmul(x,w)\n",
    "yp.shape\n",
    "\n",
    "loss = (1/4) * ((yp-y) ** 2).sum()\n",
    "loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 W [[0.0792]] Loss 3.6894726400000004\n",
      "1 W [[0.117616]] Loss 3.543369523456\n",
      "2 W [[0.15526368]] Loss 3.4030520903271424\n",
      "3 W [[0.19215841]] Loss 3.2682912275501876\n",
      "4 W [[0.22831524]] Loss 3.1388668949392002\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1,2]])\n",
    "data\n",
    "x = data[:, 0:1]\n",
    "y = data[:, 1:]\n",
    "\n",
    "w = np.array([[0]])\n",
    "\n",
    "loss = ((np.matmul(x,w) - y) ** 2 ).sum()\n",
    "loss\n",
    "\n",
    "dL = 2 * w - 4\n",
    "d = 0.01\n",
    "w = w - d  * dL\n",
    "w\n",
    "#gradient descent\n",
    "for i in range(5):\n",
    "    dL = 2*w-4\n",
    "    w = w-d*dL\n",
    "    loss = ((np.matmul(x,w) - y) ** 2 ).sum()\n",
    "    print(i, \"W\", w, \"Loss\", loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[1.3786535]] 2.585372\n",
      "1 [[1.3786535]] 2.482991\n",
      "2 [[1.3786535]] 2.3846645\n",
      "3 [[1.3786535]] 2.290232\n",
      "4 [[1.3786535]] 2.1995387\n",
      "5 [[1.3786535]] 2.112437\n",
      "6 [[1.3786535]] 2.0287845\n",
      "7 [[1.3786535]] 1.9484446\n",
      "8 [[1.3786535]] 1.8712864\n",
      "9 [[1.3786535]] 1.7971835\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1,2]], dtype = np.float32)\n",
    "x = data[:, 0:1]\n",
    "y = data[:, 1:]\n",
    "h = tf.matmul(x,w) # yp is also hypothesis\n",
    "L = tf.reduce_mean(tf.square(h-y))\n",
    "w = tf.Variable(tf.random_normal([1,1]), name = \"weight\")\n",
    "\n",
    "opti = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = opti.minimize(L)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(10):\n",
    "    sess.run(train)\n",
    "    print(i, sess.run(w), sess.run(L))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.20000005 [[1.3999999]]\n",
      "1 0.19999997 [[1.4]]\n",
      "2 0.2 [[1.4000001]]\n",
      "3 0.19999997 [[1.4]]\n",
      "4 0.2 [[1.4000001]]\n",
      "5 0.19999997 [[1.4]]\n",
      "6 0.2 [[1.4000001]]\n",
      "7 0.19999997 [[1.4]]\n",
      "8 0.2 [[1.4000001]]\n",
      "9 0.19999997 [[1.4]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1,2], [3,4]], dtype = np.float32)\n",
    "x = data[:, 0:1]\n",
    "y = data[:, 1:]\n",
    "\n",
    "data.shape\n",
    "\n",
    "fx = data[0:1, 0:1]\n",
    "fy = data[0:1, 1:2]\n",
    "\n",
    "px = tf.placeholder(tf.float32, shape = [2,1])\n",
    "py = tf.placeholder(tf.float32, shape = [2,1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([1,1]), name = \"weight\")\n",
    "h = tf.matmul(px, w)\n",
    "loss = tf.reduce_mean(tf.square(h - py))\n",
    "\n",
    "opti = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = opti.minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(10):\n",
    "    feed = {px:x, py:y}\n",
    "    sess.run(train, feed_dict = feed)\n",
    "    print(i, sess.run(loss, feed_dict = feed), sess.run(w))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 39577.984 [[14.914543 ]\n",
      " [ 7.1379304]\n",
      " [20.403524 ]]\n",
      "1 4556262.0 [[-155.00006 ]\n",
      " [ -68.500435]\n",
      " [-220.9528  ]]\n",
      "2 524528420.0 [[1668.7078 ]\n",
      " [ 740.76904]\n",
      " [2368.9744 ]]\n",
      "3 60385055000.0 [[-17898.518]\n",
      " [ -7943.52 ]\n",
      " [-25419.514]]\n",
      "4 6951681400000.0 [[192048.48 ]\n",
      " [ 85234.055]\n",
      " [272737.7  ]]\n",
      "5 800295300000000.0 [[-2060581.5 ]\n",
      " [ -914516.75]\n",
      " [-2926345.  ]]\n",
      "6 9.213204e+16 [[22109052.]\n",
      " [ 9812327.]\n",
      " [31398272.]]\n",
      "7 1.0606476e+19 [[-2.3721949e+08]\n",
      " [-1.0528154e+08]\n",
      " [-3.3688829e+08]]\n",
      "8 1.2210446e+21 [[2.5452506e+09]\n",
      " [1.1296201e+09]\n",
      " [3.6146491e+09]]\n",
      "9 1.40569765e+23 [[-2.7309314e+10]\n",
      " [-1.2120279e+10]\n",
      " [-3.8783439e+10]]\n",
      "10 1.6182752e+25 [[2.9301578e+11]\n",
      " [1.3004477e+11]\n",
      " [4.1612761e+11]]\n",
      "11 1.8629994e+27 [[-3.1439176e+12]\n",
      " [-1.3953175e+12]\n",
      " [-4.4648487e+12]]\n",
      "12 2.1447323e+29 [[3.3732717e+13]\n",
      " [1.4971084e+13]\n",
      " [4.7905671e+13]]\n",
      "13 2.4690704e+31 [[-3.6193579e+14]\n",
      " [-1.6063250e+14]\n",
      " [-5.1400474e+14]]\n",
      "14 2.842457e+33 [[3.8833967e+15]\n",
      " [1.7235092e+15]\n",
      " [5.5150231e+15]]\n",
      "15 3.2723093e+35 [[-4.1666972e+16]\n",
      " [-1.8492424e+16]\n",
      " [-5.9173538e+16]]\n",
      "16 3.7671665e+37 [[4.4706658e+17]\n",
      " [1.9841479e+17]\n",
      " [6.3490357e+17]]\n",
      "17 inf [[-4.796809e+18]\n",
      " [-2.128895e+18]\n",
      " [-6.812209e+18]]\n",
      "18 inf [[5.146745e+19]\n",
      " [2.284202e+19]\n",
      " [7.309172e+19]]\n",
      "19 inf [[-5.5222087e+20]\n",
      " [-2.4508385e+20]\n",
      " [-7.8423890e+20]]\n",
      "20 inf [[5.9250635e+21]\n",
      " [2.6296313e+21]\n",
      " [8.4145058e+21]]\n",
      "21 inf [[-6.3573078e+22]\n",
      " [-2.8214676e+22]\n",
      " [-9.0283581e+22]]\n",
      "22 inf [[6.8210843e+23]\n",
      " [3.0272988e+23]\n",
      " [9.6869928e+23]]\n",
      "23 inf [[-7.3186950e+24]\n",
      " [-3.2481459e+24]\n",
      " [-1.0393676e+25]]\n",
      "24 inf [[7.8526056e+25]\n",
      " [3.4851037e+25]\n",
      " [1.1151914e+26]]\n",
      "25 inf [[-8.4254677e+26]\n",
      " [-3.7393483e+26]\n",
      " [-1.1965466e+27]]\n",
      "26 inf [[9.0401206e+27]\n",
      " [4.0121403e+27]\n",
      " [1.2838368e+28]]\n",
      "27 inf [[-9.6996142e+28]\n",
      " [-4.3048333e+28]\n",
      " [-1.3774948e+29]]\n",
      "28 inf [[1.0407218e+30]\n",
      " [4.6188783e+29]\n",
      " [1.4779856e+30]]\n",
      "29 inf [[-1.1166443e+31]\n",
      " [-4.9558333e+30]\n",
      " [-1.5858072e+31]]\n",
      "30 inf [[1.1981055e+32]\n",
      " [5.3173708e+31]\n",
      " [1.7014948e+32]]\n",
      "31 inf [[-1.28550936e+33]\n",
      " [-5.70528304e+32]\n",
      " [-1.82562190e+33]]\n",
      "32 inf [[1.3792896e+34]\n",
      " [6.1214928e+33]\n",
      " [1.9588044e+34]]\n",
      "33 inf [[-1.4799114e+35]\n",
      " [-6.5680662e+34]\n",
      " [-2.1017029e+35]]\n",
      "34 inf [[1.5878737e+36]\n",
      " [7.0472199e+35]\n",
      " [2.2550259e+36]]\n",
      "35 inf [[-1.7037118e+37]\n",
      " [-7.5613279e+36]\n",
      " [-2.4195338e+37]]\n",
      "36 inf [[inf]\n",
      " [inf]\n",
      " [inf]]\n",
      "37 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "38 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "39 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "40 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "41 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "42 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "43 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "44 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "45 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "46 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "47 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "48 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "49 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "50 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "51 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "52 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "53 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "54 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "55 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "56 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "57 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "58 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "59 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "60 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "61 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "62 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "63 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "64 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "65 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "66 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "67 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "68 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "69 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "70 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "71 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "72 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "73 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "74 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "75 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "76 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "77 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "78 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "79 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "80 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "81 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "82 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "83 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "84 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "85 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "86 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "87 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "88 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "89 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "90 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "91 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "92 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "93 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "94 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "95 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "96 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "97 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "98 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "99 nan [[nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1,2,3,1], [4,3,7,2], [3,3,3,2], [7,1,9,3]])\n",
    "\n",
    "x = data[:, 0:3]\n",
    "y = data[:, 3:]\n",
    "\n",
    "px = tf.placeholder(tf.float32, shape = [None,3])\n",
    "py = tf.placeholder(tf.float32, shape = [None,1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([3,1]), name = \"weight\")\n",
    "h = tf.matmul(px, w)\n",
    "loss = tf.reduce_mean(tf.square(h - py))\n",
    "\n",
    "opti = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = opti.minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(100):\n",
    "    feed= {px:x, py:y}\n",
    "    sess.run(train, feed_dict = feed)\n",
    "    print(i, sess.run(loss, feed_dict = feed), sess.run(w))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
